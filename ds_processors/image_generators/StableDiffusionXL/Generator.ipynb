{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32903507-12ba-46a0-98d6-7f6e478297ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_clip = \"A photograph of a serene urban scene features a green clock on a pole, surrounded by a brick sidewalk, trees, and parked bicycles. Two men converse on the sidewalk, wearing various attire, including red shirts, grey hoodies, and sneakers. Cars and a white truck are parked along the street, with a parking meter on the curb.\"\n",
    "\n",
    "prompt_t5 = \"The scene depicts a vibrant and bustling urban setting, with a tall, green clock standing prominently on the sidewalk. The clock is surrounded by a variety of people, including two men conversing on the sidewalk, one wearing a red shirt and the other a grey hoodie. The men are standing on a brick-paved sidewalk, lined with trees that have sparse foliage. In the background, a white truck is parked on the curb, with bicycles chained to a pole nearby. A parking meter stands on the sidewalk, with a yellow top and a few coins inserted. To the left of the clock, a white work truck is parked, with a red vehicle parked behind it. A brick building with a white canopy stands nearby, with a black sign above the entrance. The building's exterior is made of white bricks, with a few windows and a door. A tall, metal light post stands nearby, casting a warm glow over the scene. The atmosphere is lively, with the sound of people chatting and the hum of traffic in the background. The sun is shining brightly, casting long shadows across the sidewalk and buildings. The overall impression is one of a thriving urban community, with a mix of old and new architecture and a sense of energy and activity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8aefbf-049e-4c49-aa19-dcd85914b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "import os\n",
    "\n",
    "repo_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "path_root = os.getcwd()\n",
    "cache_dir = os.path.join(path_root, \"cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pipeline_text2image = StableDiffusionXLPipeline.from_pretrained(\n",
    "    repo_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True,\n",
    "    cache_dir=cache_dir\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59b31d-e1a4-404b-b269-2155861e1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "base_repo_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_repo_id = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "path_root = os.getcwd()\n",
    "cache_dir = os.path.join(path_root, \"cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# .to(device)\n",
    "\n",
    "base = DiffusionPipeline.from_pretrained(\n",
    "    base_repo_id, torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "base.enable_model_cpu_offload(gpu_id=0)\n",
    "\n",
    "refiner = DiffusionPipeline.from_pretrained(\n",
    "    refiner_repo_id,\n",
    "    text_encoder_2=base.text_encoder_2,\n",
    "    vae=base.vae,\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    variant=\"fp16\",\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "refiner.enable_model_cpu_offload(gpu_id=0)\n",
    "\n",
    "# base.unet = torch.compile(base.unet, mode=\"reduce-overhead\", fullgraph=True)\n",
    "# refiner.unet = torch.compile(refiner.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8bc39c-a356-4a00-8963-4f6c705988cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_base = base(\n",
    "    prompt=prompt_clip,\n",
    "    num_inference_steps=50,\n",
    "    denoising_end=0.8,\n",
    "    guidance_scale=8.0,\n",
    "    output_type=\"latent\"\n",
    ").images \n",
    "image = refiner( \n",
    "    prompt=prompt_clip,\n",
    "    num_inference_steps=50,\n",
    "    denoising_start=0.8,\n",
    "    guidance_scale=8.0,\n",
    "    image=img_base\n",
    ").images[0]\n",
    "image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5405b0b-2000-413d-88f3-6d520a78e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generator as gen\n",
    "import os, torch\n",
    "\n",
    "base_repo_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "refiner_repo_id = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
    "path_root = os.getcwd()\n",
    "cache_dir = os.path.join(path_root, \"cache\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base, refiner = gen.get_sdxl_pipeline(base_repo_id, refiner_repo_id, cache_dir, gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4930382-0961-4a35-95d9-7129c2052b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [prompt_clip, prompt_clip]\n",
    "num_inference_steps = 50\n",
    "\n",
    "images = gen.run_sdxl_t2i(base, refiner, num_inference_steps, prompts, manual_seed=True, seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d1251-c9d2-4765-b439-4446a7447044",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/jovyan/3MDBench/data/IMAGEs/VISUAL_GENOME/selected/1.jpg\"\n",
    "prompts = [prompt_clip, prompt_clip]\n",
    "num_inference_steps = 50\n",
    "img_width = img_height = 1024\n",
    "\n",
    "images = gen.run_sdxl_imi(refiner, num_inference_steps, img_width, img_height, prompts, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01152457-faaf-4cd4-89e5-8b2ca1fad5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d9e29-32fb-444d-8049-be4d760a241e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
