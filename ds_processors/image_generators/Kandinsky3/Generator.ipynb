{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdacbbc8-6d55-4186-b5ce-69f47665f527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/jovyan/DFBench/data/IMAGEs/MSCOCO/captions.txt\", \"r\") as caption_file:\n",
    "    caption_dict = json.load(caption_file)\n",
    "len(caption_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59cc94b-81cc-4abc-bbec-04a79e146ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"In this serene bathroom, a pristine white bathtub takes center stage, positioned directly \"\\\n",
    "# \"beneath a mirror that stretches across the wall. The room is clad in gleaming white tiles, which reflect the soft light and \"\\\n",
    "# \"create a sense of calm. A glass shower door adorns the bathtub, adding a touch of modernity to the space. A few plush towels \"\\\n",
    "# \"are carefully laid out nearby, with one draped casually over the side of the tub, ready for use. To complete the tranquil \"\\\n",
    "# \"atmosphere, a mirror stands adjacent to the tub, its reflective surface bouncing light and creating the illusion of a more \"\\\n",
    "# \"spacious area.\"\n",
    "# prompt1 = \"The image shows a modern bathroom interior. It features a large bathtub with a glass enclosure, a showerhead mounted on the wall above it, and a towel rack with several white towels hanging on it. There is a window with a frosted glass covering, allowing natural light to enter the room while maintaining privacy. The walls are tiled with white and black tiles, and the floor is also tiled, giving the space a clean and contemporary look.\"\n",
    "prompt = \"A scene that depicts a vibrant and bustling urban setting, with a tall, green clock standing prominently on the sidewalk. The clock is surrounded by a variety of people, including two men conversing on the sidewalk, one wearing a red shirt and the other a grey hoodie. The men are standing on a brick-paved sidewalk, lined with trees that have sparse foliage. In the background, a white truck is parked on the curb, with bicycles chained to a pole nearby. A parking meter stands on the sidewalk, with a yellow top and a few coins inserted. To the left of the clock, a white work truck is parked, with a red vehicle parked behind it. A brick building with a white canopy stands nearby, with a black sign above the entrance. The building's exterior is made of white bricks, with a few windows and a door. A tall, metal light post stands nearby, casting a warm glow over the scene. The atmosphere is lively, with the sound of people chatting and the hum of traffic in the background. The sun is shining brightly, casting long shadows across the sidewalk and buildings. The overall impression is one of a thriving urban community, with a mix of old and new architecture and a sense of energy and activity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954bf36-4bce-47f0-a0f9-26fcfd6e5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "parent_path = os.getcwd()\n",
    "cache_dir=os.path.join(parent_path, \"cache\")\n",
    "\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"kandinsky-community/kandinsky-3\", variant=\"fp16\", torch_dtype=torch.float16,\n",
    "                                                 cache_dir=cache_dir,\n",
    "                                                 use_safetensors=True).to(\"cuda\")\n",
    "# to(\"cuda\") can not be used with cpu_offload()\n",
    "# pipe.enable_model_cpu_offload()\n",
    "# pipe.unet = torch.compile(pipe.unet, mode=\"reduce-overhead\", fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3249f-0f41-4e0b-b604-241edb6d68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.scheduler # DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3b1ced-d62b-41d9-ade6-8af4ab7f5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img_path = \"/home/jovyan/DFBench/data/IMAGEs/MSCOCO/selected/000000377132.jpg\"\n",
    "img = Image.open(img_path).resize((512, 512))\n",
    "img_width, img_height = img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfafcc-fc0c-4293-be7d-5873b79a4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = torch.Generator(device=\"cpu\").manual_seed(8) , generator=generator\n",
    "image = pipe(prompt, num_inference_steps=25, width=img_width, height=img_height).images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba21cfa6-bf81-4db1-8dfc-b5cd44fed135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "image_tensor = pil_to_tensor(image).type(torch.uint8)\n",
    "img_tensor = pil_to_tensor(img).type(torch.uint8)\n",
    "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "img_tensor = torch.unsqueeze(img_tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363fff4-173e-4d4f-a891-ae61ad7ed64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94a0df-8cfa-4ad2-bb9c-9e7a84154115",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2c6c0-0e72-4da5-88bf-aa4e64b04e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image-to-image generation\n",
    "\n",
    "from diffusers import AutoPipelineForImage2Image\n",
    "from diffusers.utils import load_image\n",
    "import torch\n",
    "import os\n",
    "\n",
    "parent_path = os.getcwd()\n",
    "cache_dir=os.path.join(parent_path, \"cache\")\n",
    "\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-3\", variant=\"fp16\", torch_dtype=torch.float16,\n",
    "    cache_dir=cache_dir, use_safetensors=True\n",
    ").to(\"cuda\")\n",
    "# to(\"cuda\") can not be used with cpu_offload()\n",
    "# pipe.enable_model_cpu_offload()\n",
    "\n",
    "# prompt = \"A painting of the inside of a subway train with tiny raccoons.\"\n",
    "# image = load_image(\n",
    "#     \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/kandinsky3/t2i.png\"\n",
    "# )\n",
    "\n",
    "# generator = torch.Generator(device=\"cpu\").manual_seed(0)\n",
    "image = pipe(prompt, image=img, strength=0.35, num_inference_steps=25,\n",
    "             width=img_width, height=img_height).images[0] # lower the strength, higher the image influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470138d-e640-486c-a4cd-d8b38c517da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Generator as gen\n",
    "import torch\n",
    "import os\n",
    "\n",
    "parent_path = os.getcwd()\n",
    "cache_dir=os.path.join(parent_path, \"cache\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "repo_id = \"kandinsky-community/kandinsky-3\"\n",
    "variant= \"fp16\"\n",
    "print(cache_dir)\n",
    "num_inference_steps = 30\n",
    "prompts = [prompt, prompt]\n",
    "img_path = \"/home/jovyan/DFBench/data/IMAGEs/VISUAL_GENOME/selected/1.jpg\"\n",
    "t2i_or_i2i = True\n",
    "img_width = 512\n",
    "img_height = 512\n",
    "\n",
    "pipe = gen.get_kandinsky3_pipeline(repo_id, variant, cache_dir, t2i_or_i2i)\n",
    "images = gen.run_kandinsky3_t2i(pipe, num_inference_steps, img_width, img_height, prompts, manual_seed=False, seed=None)\n",
    "# images = gen.run_kandinsky3_i2i(pipe, num_inference_steps, img_width, img_height, prompts, img_path, manual_seed=False, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f92cb0-b798-4403-b190-741db69c950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d373d-dccd-4f3d-b5b4-f7de4df01ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Image\n",
    "# im = Image.open(<your image>)\n",
    "# width, height = im.size   # Get dimensions\n",
    "\n",
    "# left = (width - new_width)/2\n",
    "# top = (height - new_height)/2\n",
    "# right = (width + new_width)/2\n",
    "# bottom = (height + new_height)/2\n",
    "\n",
    "# # Crop the center of the image\n",
    "# im = im.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642617f-d166-4faa-9693-8ae942e1ba03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
